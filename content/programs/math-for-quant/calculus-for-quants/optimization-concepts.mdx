# Optimization Concepts

## 1. Why Optimization Matters in Quant Finance

Optimization is one of the most important mathematical tools in quantitative finance.

Every quant workflow relies on it:

- **Maximizing Sharpe Ratio**
- **Optimizing portfolios under constraints**
- **Calibrating models to market data**
- **Minimizing error between models and observations**
- **Choosing optimal hedges**
- **Training machine learning models**
- **Fitting yield curves**
- **Risk budgeting and capital allocation**

If calculus tells us how things change, **optimization tells us where to go.**

At its core, optimization answers:

> "What input values give the best possible outcome, given my objective and constraints?"

This lesson builds the foundation that almost every quant uses daily.

---

## 2. Objective Functions

In optimization, you always have an **objective**:

$$
\text{maximize or minimize } f(x).
$$

### Examples:

- Maximize Sharpe ratio
- Minimize portfolio variance
- Minimize hedging error
- Minimize calibration loss

### Domain

You also choose where $x$ lives:

- $\mathbb{R}$
- $\mathbb{R}^n$
- A simplex (weights sum to 1)
- A feasible region defined by constraints

---

## 3. Stationary Points: Where Derivatives Vanish

For a smooth function in one variable:

$$
f'(x^*) = 0
$$

is a candidate for:

- local minimum
- local maximum
- saddle point

In several variables, the **gradient** generalizes the derivative:

$$
\nabla f(x^*) = 0.
$$

This condition is fundamental for locating optimal points.

---

## 4. Gradient: The Direction of Steepest Ascent

For multivariable functions:

$$
\nabla f(x) = \begin{bmatrix}
\frac{\partial f}{\partial x_1} \\
\frac{\partial f}{\partial x_2} \\
\vdots \\
\frac{\partial f}{\partial x_n}
\end{bmatrix}.
$$

### Key fact:

- The gradient points in the direction where the function **increases** the fastest.
- The negative gradient points in the direction of **steepest decrease**.

This is why **gradient descent** works.

---

## 5. Gradient Descent: The Workhorse of Quant and ML

Gradient descent updates parameters iteratively:

$$
x_{k+1} = x_k - \alpha \nabla f(x_k)
$$

where:

- $\alpha$ is the learning rate / step size
- $\nabla f(x_k)$ is the gradient at the current point

**Interpretation:** Move downhill in the direction of steepest decrease.

### Why it's used everywhere

- Efficient for high-dimensional problems
- Works with noisy gradients (Monte Carlo)
- Foundation of machine learning
- Essential for portfolio optimization with many assets
- Works even when we only have numerical gradients

---

## 6. Convex vs Non-Convex Optimization

### Convex functions

A function is **convex** if:

$$
f(\lambda x + (1-\lambda)y) \le \lambda f(x) + (1-\lambda)f(y)
$$

for all $0 \le \lambda \le 1$.

### Why convexity matters

- Every local minimum is a global minimum
- Optimization is predictable
- Problems have unique solutions
- Portfolio variance is convex
- Many risk measures are convex

**Convex problems are the "easy" problems of quantitative finance.**

### Non-convex functions

- Multiple local minima
- Harder to optimize
- Training neural networks
- Calibrating stochastic models
- Utility maximization in certain forms

Non-convex optimization requires better initialization and more care.

---

## 7. Line Search: Choosing Step Size

Gradient descent only works well if the step size $\alpha$ is appropriate.

- **Too big:** overshoot the minimum, diverge
- **Too small:** extremely slow convergence

A **line search** method chooses $\alpha$ that reduces the objective enough.

In many quant problems, a simple decaying step size or backtracking search is enough.

---

## 8. Constraints: Optimization With Rules

In finance, optimization almost always has **constraints**:

- weights sum to 1
- weights must be nonnegative
- leverage limits
- exposure limits
- regulatory or risk constraints

### Two main types:

**Equality constraints**
$$
g_i(x) = 0
$$

**Inequality constraints**
$$
h_j(x) \le 0
$$

---

## 9. Lagrange Multipliers (Concept Only)

To solve constrained optimization:

- Introduce a Lagrange multiplier for each constraint
- Solve a system where gradients must align with constraint normals

**Lagrangian:**

$$
L(x, \lambda) = f(x) + \lambda g(x)
$$

**Stationarity condition:**

$$
\nabla_x L(x, \lambda) = 0.
$$

This is the foundation for modern convex optimization and numerical solvers.

---

## 10. Quant Application 1: Portfolio Variance Minimization

Let $w$ be the vector of weights in $n$ assets.
Portfolio variance:

$$
\sigma_p^2 = w^T \Sigma w.
$$

**Goal:** minimize $w^T \Sigma w$ subject to $w^T \mathbf{1} = 1$.

This is a quadratic objective with a linear constraint — a classic convex optimization problem.

The solution has a closed form using Lagrange multipliers:

$$
w^* = \frac{\Sigma^{-1} \mathbf{1}}{\mathbf{1}^T \Sigma^{-1} \mathbf{1}}.
$$

This is the **minimum variance portfolio**.

Every quant should know this formula.

---

## 11. Quant Application 2: Maximizing Sharpe Ratio

Sharpe ratio:

$$
S(w) = \frac{w^T \mu}{\sqrt{w^T \Sigma w}}.
$$

Equivalent optimization:

maximize ratio → maximize square of ratio →
$$
\text{maximize } \frac{(w^T \mu)^2}{w^T \Sigma w}
$$

This is also a constrained optimization problem and has a closed form in the unconstrained case.

In practice, most desks:

- maximize Sharpe numerically,
- use gradient-based methods,
- or use numerical finite differences for the gradient.

---

## 12. Quant Application 3: Calibrating a Model

Model calibration minimizes the error between model outputs and observed market prices.

**Objective function:**

$$
f(\theta) = \sum_i (C_{\text{model}}(\theta) - C_{\text{market}})^2.
$$

**Goal:** find $\theta$ that minimizes error.

This is:

- generally non-convex,
- solved via gradient descent,
- or quasi-Newton methods
- or stochastic gradient descent when data is large.

**Calibration is optimization in disguise.**

---

## 13. Quant Application 4: Numerical Gradient (Finite Differences)

Sometimes we don't have a formula for the gradient.
Then we compute it numerically:

$$
\frac{\partial f}{\partial x_i} \approx \frac{f(x + h e_i) - f(x)}{h}.
$$

This is essential when:

- pricing models have no closed-form derivatives
- Monte Carlo simulations introduce noise
- gradients are too expensive to compute analytically

This connects optimization directly to the earlier lessons.

---

## 14. Worked Example: Gradient Descent on a Simple Function

Take:

$$
f(x) = (x - 3)^2.
$$

Gradient:

$$
f'(x) = 2(x - 3).
$$

Gradient descent update:

$$
x_{k+1} = x_k - \alpha \cdot 2(x_k - 3).
$$

If $x_0 = 0$ and $\alpha = 0.1$:

- **Step 1:** $x_1 = 0 - 0.2(-3) = 0.6$
- **Step 2:** $x_2 = 0.6 - 0.2(-2.4) = 1.08$
- **Step 3:** $x_3 = 1.08 - 0.2(-1.92) = 1.464$

The sequence moves toward the minimum at $x=3$.

This example mirrors how optimization works in real quant models.

---

## 15. Summary

- Optimization finds the best value of an objective function.
- Stationary points satisfy $f'(x)=0$ or $\nabla f(x)=0$.
- **Gradient descent** moves in the direction of steepest descent.
- Step size control is key (line search).
- Constraints require **Lagrange multipliers**.
- Portfolio optimization is a classic convex problem.
- **Sharpe ratio maximization** is widely used in quant trading.
- Calibration and numerical gradients rely heavily on optimization.

**Optimization is the mathematical backbone of real-world quantitative finance.**
